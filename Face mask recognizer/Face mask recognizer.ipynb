{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport os\nimport tensorflow as tf\nimport numpy as np\nimport json\nimport shutil\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\nbs = 16\nnum_classes=3\n\nimg_h = 224\nimg_w = 224\n\n\n# Set the seed for random operations. \n# This let our experiments to be reproducible. \nSEED = 1234\ntf.random.set_seed(SEED)  \n\n# Get current working directory\ncwd = os.getcwd()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = cwd + '/Dataset'\nif os.path.exists(path):\n  shutil.rmtree(path)\n\nos.makedirs(path)\n\n\npath = cwd + '/Dataset/test'\nif not os.path.exists(path):\n    os.makedirs(path)\n\npath = cwd + '/Dataset/training'\nif not os.path.exists(path):\n    os.makedirs(path)\n\npath = cwd + '/Dataset/training/no_one'\nif not os.path.exists(path):\n    os.makedirs(path)\n\npath = cwd + '/Dataset/training/someone'\nif not os.path.exists(path):\n    os.makedirs(path)\n\npath = cwd + '/Dataset/training/everyone'\nif not os.path.exists(path):\n    os.makedirs(path)\n\npath = cwd + '/Dataset/validation'\nif not os.path.exists(path):\n    os.makedirs(path)\n\npath = cwd + '/Dataset/validation/no_one'\nif not os.path.exists(path):\n    os.makedirs(path)\n\npath = cwd + '/Dataset/validation/someone'\nif not os.path.exists(path):\n    os.makedirs(path)\n\npath = cwd + '/Dataset/validation/everyone'\nif not os.path.exists(path):\n    os.makedirs(path)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/artificial-neural-networks-and-deep-learning-2020/MaskDataset/train_gt.json') as file:\n    data = json.load(file)\n\n\n    \n    \n#we put the images from MaskDataset to Dataset.\n#and organize them in subdirectories. There is a subdirectory for each class\n \n\n#training set\nsource = '../input/artificial-neural-networks-and-deep-learning-2020/MaskDataset/training'\ndest = cwd + '/Dataset/training'\n\nfor filename in os.listdir(source):\n  if data[filename] == 0:\n    a=shutil.copy(source + '/' + filename,  dest + '/no_one/' + filename)\n\n  elif data[filename] == 1:\n    a=shutil.copy(source + '/' + filename, dest + '/everyone/' + filename)\n\n  else:\n    a=shutil.copy(source + '/' + filename, dest + '/someone/' + filename)\n\n\n#test set\nsource =  '../input/artificial-neural-networks-and-deep-learning-2020/MaskDataset/test'\ndest = cwd + '/Dataset/test'\n\nfor filename in os.listdir(source):\n    a=shutil.copy(source + '/' + filename,  dest + '/' + filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create validation set 20/80.\n\n#Per ora non è randomico, ma sempre lo stesso a dogni run. così da ripetere gli esperimenti\n#forse dovremmo farlo randomico? in tal caso basta fare uno shuffle ogni volta, prima di creare validation.\n\n#se si runna più volte questa cella, un altro 20% degli elementi restanti nel training, vanno nel validation.\n#se si vuole ricreare il validation, ri runnare prima la cella sopra.\n#se si vuole svuotare e ricreare tutto il Datset, ri runnare da 2 celle sopra\n\nsource = cwd + '/Dataset/training'\ndest = cwd + '/Dataset/validation'\n\n\n#metto un contatore al 20% della dimensione di ogni classe del training. \n#fino a che non è 0, sposto dal training al validation.\ncount = len(os.listdir(source + '/no_one')) * 0.2\nfor filename in os.listdir(source + '/no_one'):\n    if count > 0:\n        count -= 1\n        shutil.move(source + '/no_one/' + filename, dest + '/no_one/' + filename)\n        \n        \n        \ncount = len(os.listdir(source + '/someone')) * 0.2\nfor filename in os.listdir(source + '/someone'):\n    if count > 0:\n        count -= 1\n        shutil.move(source + '/someone/' + filename, dest + '/someone/' + filename)\n        \n        \n        \ncount = len(os.listdir(source + '/everyone')) * 0.2\nfor filename in os.listdir(source + '/everyone'):\n    if count > 0:\n        count -= 1\n        shutil.move(source + '/everyone/' + filename, dest + '/everyone/' + filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"apply_data_augmentation = True\n\n# Create training ImageDataGenerator object\nif apply_data_augmentation:\n    train_data_gen = ImageDataGenerator(rotation_range=10,\n                                        width_shift_range=10,\n                                        height_shift_range=10,\n                                        zoom_range=0.3,\n                                        horizontal_flip=True,\n                                        vertical_flip=True,\n                                        fill_mode='constant',\n                                        cval=0,\n                                        rescale=1./255)\nelse:\n#preparing a Image Data Generator for training\n    train_data_gen = ImageDataGenerator(rescale=1./255)\n    \n#Now I prepare the ImageDataGenerator also for testing and validation\nvalid_data_gen = ImageDataGenerator(rescale=1./255)\ntest_data_gen = ImageDataGenerator(rescale=1./255)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating datasets objects\n#Lo so che le immagini sono di dimensione variabile, ma non so bene come farle passare di qua se no\n\n\n#manage classes\nclasses = ['no_one','everyone','someone']\n\n\ntraining_dir = cwd + '/Dataset/training'\nvalidation_dir = cwd + '/Dataset/validation'\ntest_dir = cwd + '/Dataset/test'\n\n#Now I select the data\ntrain_gen = train_data_gen.flow_from_directory(training_dir,\n                                               color_mode='rgb',\n                                               batch_size=bs,  \n                                               classes = classes,\n                                               class_mode='categorical',\n                                               target_size=(img_h, img_w),\n                                               shuffle=True,\n                                               seed=SEED)  # targets are directly converted into one-hot vectors\n\nvalid_gen = valid_data_gen.flow_from_directory(validation_dir,\n                                               color_mode='rgb',\n                                               batch_size=bs, \n                                               classes = classes,\n                                               class_mode='categorical',\n                                               target_size=(img_h, img_w),\n                                               shuffle=True,\n                                               seed=SEED)\n\n#test_gen = test_data_gen.flow_from_directory(test_dir,\n#                                             color_mode='rgb',\n#                                             batch_size=bs, \n#                                             class_mode='categorical',\n#                                             shuffle=False,\n#                                             seed=SEED)\ntrain_gen.class_indices","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating datasets objects\n#Lo so che le immagini sono di dimensione variabile, ma non so bene come farle passare di qua se no\n\n\ntrain_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                               output_shapes=(tf.TensorShape([None, img_h, img_w, 3]), tf.TensorShape([None, num_classes])))\ntrain_dataset.repeat()\n\nvalid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n                                               output_types=(tf.float32, tf.float32),\n                                               output_shapes=(tf.TensorShape([None, img_h, img_w, 3]), tf.TensorShape([None, num_classes])))\n\n# Repeat\nvalid_dataset = valid_dataset.repeat()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    finetuning = True\n\n    if finetuning:\n        freeze_until = 15 # layer from which we want to fine-tune\n\n        for layer in net.layers[:freeze_until]:\n            layer.trainable = False\n    else:\n        net.trainable = False\n\n    model = tf.keras.Sequential()\n    model.add(net)\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(units=500, activation=tf.keras.activations.relu)) #, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n   # model.add(tf.keras.layers.Dense(units=500, activation=tf.keras.activations.relu ))\n    model.add(tf.keras.layers.Dropout(0.2))\n    model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n\n    # Visualize created model as a table\n    model.summary()\n\n# Visualize initialized weights\n#model.weights","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Loss\nloss = tf.keras.losses.CategoricalCrossentropy()\n\n# learning rate\nlr = 1e-4\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n# -------------------\n\n# Validation metrics\n# ------------------\n\nmetrics = ['accuracy']\n# ------------------\n\n# Compile Model\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = []\nearly_stop = True\nif early_stop:\n    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n    callbacks.append(es_callback)\n\n#ckpt_dir = os.path.join(cwd, 'ckpts')\n#if not os.path.exists(ckpt_dir):\n #   os.makedirs(ckpt_dir)\n\n   # ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n                                                   #save_weights_only=True)  # False to save the model directly\n#callbacks.append(ckpt_callback)\n\n#model.load_weights(cwd + '/Weights/cp.ckpt')\nmodel.fit(x = train_dataset,\n          epochs = 40,  #### set repeat in training dataset\n          steps_per_epoch = len(train_gen),\n          validation_data = valid_dataset,\n          validation_steps = len(valid_gen), \n          callbacks = callbacks)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ahhhhh help\nvetter\n","metadata":{}},{"cell_type":"code","source":"from datetime import datetime \ndef create_csv(results, results_dir='./'):\n\n    csv_fname = 'results_'\n    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n\n    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n\n        f.write('Id,Category\\n')\n\n        for key, value in results.items():\n            f.write(key + ',' + str(value) + '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimage_filenames = next(os.walk('./Dataset/test'))[2]\n\nresults = {}\n\nfor image_name in image_filenames:\n \n   img = Image.open('./Dataset/test/'+image_name).convert('RGB')\n   img = img.resize((img_w,img_h))\n   img_array = np.array(img)\n   img_array = np.expand_dims(img_array, 0) \n   \n    \n   prediction = np.argmax(model.predict(x=img_array/255.))  # predicted class\n   \n\n   results[image_name] = prediction\n\ncreate_csv(results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}